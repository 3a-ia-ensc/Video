{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_images(images, n_line, l_col):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for i in range(n_line*l_col):\n",
    "        ax = plt.subplot(n_line, l_col, i + 1)\n",
    "        plt.imshow(images[i])\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_boxes(x, y, w, h):\n",
    "    N = 5\n",
    "    shift = list(range(-N, N+1, 2))\n",
    "    \n",
    "    pos = []\n",
    "    for i in shift:\n",
    "        new_x = x + i\n",
    "        \n",
    "        for j in shift:\n",
    "            new_y = y + j\n",
    "            \n",
    "            new_pos = (new_x, new_y, w, h)\n",
    "            pos.append(new_pos)\n",
    "            \n",
    "            # Zoom modification\n",
    "            zoom = [1.2, 0.8]\n",
    "            for z in zoom:\n",
    "                new_w, new_h = int(w*z), int(h*z)\n",
    "                new_x = new_x - (abs(new_w - w) // 2)\n",
    "                new_y = new_y - (abs(new_h - h) // 2)\n",
    "                \n",
    "                pos.append((new_x, new_y, new_w, new_h))\n",
    "            \n",
    "    return pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_bounding_box(path):\n",
    "    boxes = {}\n",
    "    m = re.search('VIDEOS/(.+)\\.mp4', path)\n",
    "    filename = m.group(1)\n",
    "    \n",
    "    f = open(f'../GT/{filename}_2_bboxes.txt', 'r')\n",
    "    lines = f.readlines()\n",
    "    \n",
    "    for l in lines:\n",
    "        elmts = l.split(' ')\n",
    "        frame = int(elmts[0])\n",
    "        \n",
    "        if elmts[1] == '1':\n",
    "            boxes[frame] = (int(elmts[2]), int(elmts[3]), int(elmts[4]), int(elmts[5]))\n",
    "            \n",
    "    return boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('../models/custom_13_12_2020', custom_objects=None, compile=True, options=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = { 0: 'bol', 1: 'coca', 2: 'lait', 3: 'riz', 4: 'sucre' }\n",
    "def get_images(filename):\n",
    "    predict_boxes = {}\n",
    "    \n",
    "    # on récupère les boundings box du fichier\n",
    "    boxes = read_bounding_box(filename)\n",
    "    \n",
    "    # on ouvre le fichier\n",
    "    cap = cv2.VideoCapture(filename)\n",
    "    nframes = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    if(not cap.isOpened()):\n",
    "        print(\"ERROR: unable to read video:\", video_filename)\n",
    "        sys.exit()\n",
    "    \n",
    "    print(f'Loading {nframes} frames')\n",
    "    print(len(boxes))\n",
    "    \n",
    "    if 'CanOfCocaCola' in filename:\n",
    "        label = 1\n",
    "    elif 'MilkBottle' in filename:\n",
    "        label = 2\n",
    "    elif 'Bowl' in filename:\n",
    "        label = 0\n",
    "    elif 'Rice' in filename:\n",
    "        label = 3\n",
    "    elif 'Sugar' in filename:\n",
    "        label = 4\n",
    "    \n",
    "    foundObj = False\n",
    "    for f in range(nframes):\n",
    "        ret, frame = cap.read()\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) # conversion BRG to RGB\n",
    "        \n",
    "        if f in boxes: # on ne regarde que les frames qui ont une bounding box\n",
    "            if not foundObj:\n",
    "                box = boxes[f] # première bounding box (= box de référence)\n",
    "            else:\n",
    "                x, y, w, h = box\n",
    "                \n",
    "                # on créé de nouvelles bouding box autour de celle de la frame précédente\n",
    "                new_boxes = build_boxes(x, y, w, h)\n",
    "                #patch = frame[y:y+h, x:x+w]\n",
    "                \n",
    "                # pour chaque nouvel box, on extrait le patch associé dans l'image\n",
    "                patches = np.zeros((0, 227, 227, 3))\n",
    "                for bb in new_boxes:\n",
    "                    x1, y1, w1, h1 = bb\n",
    "                    #new_patch = tf.expand_dims(frame[y1:y1+h1, x1:x1+w1, :], 0) \n",
    "                    new_patch = frame[y1:y1+h1, x1:x1+w1, :]\n",
    "                    new_patch = tf.image.resize(new_patch, (227, 227), method='nearest')\n",
    "                    patches = tf.concat((patches, tf.expand_dims(new_patch, 0)), axis=0)\n",
    "                \n",
    "                # on passe les patchs dans le modèle\n",
    "                pred = model.predict(patches)\n",
    "                \n",
    "                # on récupère la meilleure prédiction\n",
    "                best_pred = np.argmax(pred[:, label])\n",
    "                \n",
    "                # on récupère le patch associé à la meilleure prédiction\n",
    "                best_patch = patches[best_pred]\n",
    "                best_box = new_boxes[best_pred]\n",
    "                \n",
    "                # on modifie la current box pour la frame suivante\n",
    "                box = best_box\n",
    "                predict_boxes[f] = best_box\n",
    "                \n",
    "                \"\"\"if f == 26:\n",
    "                    a, b, c, d = best_box\n",
    "                    p = frame[b:b+d, a:a+c, :]\n",
    "                    plt.imshow(p)\n",
    "                    break\"\"\"\n",
    "                    \n",
    "            foundObj = True\n",
    "    \n",
    "    return predict_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 186 frames\n",
      "163\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "input image must be of non-zero size [Op:ResizeNearestNeighbor]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-9eedba6b74ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../VIDEOS/CanOfCocaColaPlace6Subject4.mp4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-46-8aad8e8dc92f>\u001b[0m in \u001b[0;36mget_images\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     49\u001b[0m                     \u001b[0;31m#new_patch = tf.expand_dims(frame[y1:y1+h1, x1:x1+w1, :], 0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                     \u001b[0mnew_patch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0my1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mh1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                     \u001b[0mnew_patch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_patch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m227\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m227\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'nearest'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m                     \u001b[0mpatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_patch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/ops/image_ops_impl.py\u001b[0m in \u001b[0;36mresize_images_v2\u001b[0;34m(images, size, method, preserve_aspect_ratio, antialias, name)\u001b[0m\n\u001b[1;32m   1538\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Resize method is not implemented: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1540\u001b[0;31m   return _resize_images_common(\n\u001b[0m\u001b[1;32m   1541\u001b[0m       \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1542\u001b[0m       \u001b[0mresize_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/ops/image_ops_impl.py\u001b[0m in \u001b[0;36m_resize_images_common\u001b[0;34m(images, resizer_fn, size, preserve_aspect_ratio, name, skip_resize_if_same)\u001b[0m\n\u001b[1;32m   1271\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1273\u001b[0;31m     \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresizer_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1275\u001b[0m     \u001b[0;31m# NOTE(mrry): The shape functions for the resize ops cannot unpack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/ops/image_ops_impl.py\u001b[0m in \u001b[0;36mresize_fn\u001b[0;34m(images_t, new_size)\u001b[0m\n\u001b[1;32m   1523\u001b[0m             images_t, new_size, half_pixel_centers=True)\n\u001b[1;32m   1524\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mResizeMethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNEAREST_NEIGHBOR\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1525\u001b[0;31m       return gen_image_ops.resize_nearest_neighbor(\n\u001b[0m\u001b[1;32m   1526\u001b[0m           images_t, new_size, half_pixel_centers=True)\n\u001b[1;32m   1527\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mResizeMethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBICUBIC\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/ops/gen_image_ops.py\u001b[0m in \u001b[0;36mresize_nearest_neighbor\u001b[0;34m(images, size, align_corners, half_pixel_centers, name)\u001b[0m\n\u001b[1;32m   3655\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3656\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3657\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3658\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3659\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6841\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6842\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6843\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6844\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: input image must be of non-zero size [Op:ResizeNearestNeighbor]"
     ]
    }
   ],
   "source": [
    "tracking = get_images('../VIDEOS/CanOfCocaColaPlace6Subject4.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
