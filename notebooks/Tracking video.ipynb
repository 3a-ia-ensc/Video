{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path, listdir\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from src.tracking import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3568 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale = 1.0/255.)\n",
    "test_generator = test_datagen.flow_from_directory('../DB/test', batch_size = 3568, class_mode = 'categorical', target_size = (227, 227))\n",
    "\n",
    "# On récupère les images d'un batch de la taille du dataset\n",
    "i = 0\n",
    "for image, lab in test_generator:\n",
    "    if i == 0: break # sinon le generator continue sa boucle (??)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tracking vidéo\n",
    "En partant d'une première détection de l'objet d'intérêt qui prend la forme d'une boite englobante que l'on suppose correcte, on va suivre l'objet sur les frames suivantes.\n",
    "\n",
    "Pour chaque frame, on prend la boîte englobante de la frame précédente, on va créer un set de nouvelles boîtes potentielles. On va ensuite récupérer le \"patch\" de l'image associé à chaque nouvelle boîte englobante et effectuer une prediction à l'aide du modèle précédemment créé. On conservera comme nouvelle boîte celle qui fournira la prédiction la plus précise (pourcentage le plus élevé)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on charge le modèle\n",
    "model = tf.keras.models.load_model('../models/best_models', custom_objects=None, compile=True, options=None)\n",
    "\n",
    "# le fichier sur lequel on veut travailler\n",
    "filename = '../VIDEOS/BowlPlace4Subject4.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 26s 228ms/step - loss: 0.0856 - accuracy: 0.9703 - categorical_accuracy: 0.9703 - recall: 0.9680 - precision: 0.9713\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08564037084579468,\n",
       " 0.9702914953231812,\n",
       " 0.9702914953231812,\n",
       " 0.9680493474006653,\n",
       " 0.9713160991668701]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(image, lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/186 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 186 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 186/186 [23:41<00:00,  7.64s/it]\n",
      " 12%|█▏        | 23/189 [00:00<00:00, 225.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 189 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 189/189 [10:10<00:00,  3.23s/it]\n",
      " 14%|█▎        | 28/205 [00:00<00:00, 278.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 205 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 205/205 [14:12<00:00,  4.16s/it]\n",
      " 14%|█▎        | 27/200 [00:00<00:00, 269.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 200 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [30:34<00:00,  9.17s/it]\n",
      "  0%|          | 0/141 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 141 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 141/141 [25:53<00:00, 11.02s/it]\n",
      "  7%|▋         | 16/224 [00:00<00:01, 159.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 224 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [29:27<00:00,  7.89s/it]\n",
      " 11%|█         | 22/202 [00:00<00:00, 216.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 202 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 202/202 [21:01<00:00,  6.25s/it]\n",
      " 14%|█▎        | 24/177 [00:00<00:00, 239.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 177 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 177/177 [19:30<00:00,  6.61s/it]\n",
      "  9%|▊         | 22/258 [00:00<00:01, 217.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 258 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 258/258 [28:37<00:00,  6.66s/it]\n",
      "  0%|          | 0/142 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 142 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 142/142 [18:18<00:00,  7.73s/it]\n",
      " 10%|█         | 23/226 [00:00<00:00, 229.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 226 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 226/226 [25:47<00:00,  6.85s/it]\n",
      " 15%|█▌        | 30/197 [00:00<00:00, 294.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 197 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 197/197 [13:55<00:00,  4.24s/it]\n",
      "  8%|▊         | 25/313 [00:00<00:01, 245.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 313 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [30:19<00:00,  5.81s/it]\n",
      " 17%|█▋        | 25/146 [00:00<00:00, 246.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 146 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 146/146 [16:49<00:00,  6.91s/it]\n",
      " 24%|██▎       | 27/114 [00:00<00:00, 267.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 114 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 114/114 [13:11<00:00,  6.94s/it]\n",
      " 12%|█▏        | 25/213 [00:00<00:00, 245.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 213 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 213/213 [21:58<00:00,  6.19s/it]\n",
      "  0%|          | 0/195 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 195 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 195/195 [02:38<00:00,  1.23it/s]\n",
      " 11%|█         | 28/260 [00:00<00:00, 275.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 260 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 260/260 [25:48<00:00,  5.96s/it]\n",
      " 10%|█         | 19/186 [00:00<00:00, 188.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 186 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 186/186 [25:28<00:00,  8.22s/it]\n",
      "  0%|          | 0/168 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 168 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 168/168 [24:21<00:00,  8.70s/it]\n",
      "  6%|▌         | 18/312 [00:00<00:01, 179.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 312 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [19:16<00:00,  3.71s/it]\n",
      "  9%|▊         | 26/304 [00:00<00:01, 257.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 304 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 304/304 [2:43:26<00:00, 32.26s/it]     \n",
      " 14%|█▍        | 24/167 [00:00<00:00, 239.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 167 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 167/167 [17:40<00:00,  6.35s/it]\n",
      " 23%|██▎       | 53/235 [00:00<00:01, 162.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 235 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 235/235 [26:37<00:00,  6.80s/it]\n",
      "  0%|          | 0/169 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 169 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 169/169 [15:56<00:00,  5.66s/it]\n"
     ]
    }
   ],
   "source": [
    "for file in listdir(\"../GT_test\"):\n",
    "    if file.endswith(\".txt\"):\n",
    "        m = re.search('(.+)_._bboxes\\.txt', file)\n",
    "        name = m.group(1)\n",
    "        \n",
    "        path_video = path.join('..', 'VIDEOS', name + '.mp4')\n",
    "        path_boxes = path.join('..', 'GT_test', file)\n",
    "        \n",
    "        tracking(model, path_video, path_boxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Move-to-data\n",
    "Nous implémentons ici la méthode d'apprentissage incrémental \"move-to-data\" décrite dans _Move-to-Data: A new Continual Learning approach with Deep CNNs, Application for image-class recognition_\n",
    "\n",
    "Pour chaque nouvelle image, on met à jour les poids de la dernière couche du réseau en appliquant la formule suivante \n",
    "$$w_j′=w_j+(||w_j||∗\\frac{v_i}{||v_i||} − w_j)*\\epsilon$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_to_data(image, model, epsilon, j):\n",
    "    image = tf.image.resize(image, (227, 227), method='nearest')\n",
    "    y_, _ = model(tf.expand_dims(image, axis=0))\n",
    "    w, b = model.get_layer('dense_3').get_weights()\n",
    "    \n",
    "    new_weights = w.copy()\n",
    "    \n",
    "    w_j = w[:, j]\n",
    "    new_w = w_j + (tf.norm(w_j) * (y_ / tf.norm(y_)) - w_j) * epsilon\n",
    "    new_weights[:, j] = new_w\n",
    "\n",
    "    model.get_layer('dense_3').set_weights([new_weights, b])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On modifie légèrement le modèle pour avoir les bonnes sorties du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = [layer.output for layer in model.layers]\n",
    "move_model = tf.keras.Model(output[0], [output[-2], output[-1]])\n",
    "\n",
    "move_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[\n",
    "    'accuracy', \n",
    "    'categorical_accuracy',\n",
    "    tf.keras.metrics.Recall(),\n",
    "    tf.keras.metrics.Precision()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on charge le modèle\n",
    "model_fine = tf.keras.models.load_model('../models/best_models', custom_objects=None, compile=True, options=None)\n",
    "\n",
    "for layer in model_fine.layers[:-1]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model_fine.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[\n",
    "    'accuracy', \n",
    "    'categorical_accuracy',\n",
    "    tf.keras.metrics.Recall(),\n",
    "    tf.keras.metrics.Precision()])\n",
    "        \n",
    "def fine_tuning(image, label):\n",
    "    model.fit(image, label, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "labels = []\n",
    "p = 0\n",
    "for file in listdir(\"../GT_pred\"):\n",
    "    if file.endswith(\".txt\"):\n",
    "        predicted_boxes = read_bounding_box(path.join('..', 'GT_pred', file))\n",
    "        \n",
    "        m = re.search('(.+)_pred_box\\.txt', file)\n",
    "        name = m.group(1)\n",
    "        path_video = path.join('..', 'VIDEOS', name + '.mp4')\n",
    "        \n",
    "        cap = cv2.VideoCapture(path_video)\n",
    "        nframes = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "        if 'CanOfCocaCola' in file:\n",
    "            label = 1\n",
    "        elif 'MilkBottle' in file:\n",
    "            label = 2\n",
    "        elif 'Bowl' in file:\n",
    "            label = 0\n",
    "        elif 'Rice' in file:\n",
    "            label = 3\n",
    "        elif 'Sugar' in file:\n",
    "            label = 4\n",
    "\n",
    "        for f in range(nframes):\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            f_width, f_height, _ = frame.shape\n",
    "\n",
    "            if f in predicted_boxes:\n",
    "                x, y, w, h = predicted_boxes[f]\n",
    "                patch = frame[y:y+h, x:x+w, :]\n",
    "                images.append(patch)\n",
    "                labels.append(label)\n",
    "                \n",
    "                # move_to_data(patch, move_model, 0.0001, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3180"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    perm = np.random.permutation(len(images))\n",
    "    \n",
    "    for idx in perm:\n",
    "        im = images[idx]\n",
    "        if 0 not in im.shape:\n",
    "            move_to_data(im, move_model, 0.0001, labels[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 24s 216ms/step - loss: 0.0954 - accuracy: 0.9717 - categorical_accuracy: 0.9717 - recall: 0.9692 - precision: 0.9746\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.09536933898925781,\n",
       " 0.9716928005218506,\n",
       " 0.9716928005218506,\n",
       " 0.9691703915596008,\n",
       " 0.9746335744857788]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(image, lab)                                                                                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
