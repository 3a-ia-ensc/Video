{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPool2D, Flatten, Dense, Softmax, LeakyReLU, Dropout\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://dept-info.labri.fr/~mansenca/GITW_light/DB.zip\n",
      "444981248/543730825 [=======================>......] - ETA: 27s"
     ]
    }
   ],
   "source": [
    "dataset_url = 'https://dept-info.labri.fr/~mansenca/GITW_light/DB.zip'\n",
    "data_dir = tf.keras.utils.get_file(origin=dataset_url, \n",
    "                                   fname='flower_photos', \n",
    "                                   untar=True)\n",
    "data_dir = pathlib.Path(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open('/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet vidéo\n",
    "\n",
    "## Création d'un modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = (227, 227, 3)\n",
    "input_img = Input(input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_layer = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)(input_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = Conv2D(filters=32, kernel_size=(3, 3), strides=(1, 1), padding='valid')(normalization_layer)\n",
    "r1 = LeakyReLU(alpha=0.3)(c1)\n",
    "m1 = MaxPool2D(pool_size=(2, 2), strides=None, padding='valid')(r1)\n",
    "drop1 = Dropout(0.2)\n",
    "\n",
    "c2 = Conv2D(filters=32, kernel_size=(3, 3), strides=(1, 1), padding='valid', activation='relu')(m1)\n",
    "m2 = MaxPool2D(pool_size=(2, 2), strides=None, padding='valid')(c2)\n",
    "drop2 = Dropout(0.2)\n",
    "\n",
    "c3 = Conv2D(filters=64, kernel_size=(3, 3), strides=(1, 1), padding='valid', activation='relu')(m2)\n",
    "m3 = MaxPool2D(pool_size=(2, 2), strides=None, padding='valid')(c3)\n",
    "drop1 = Dropout(0.2)\n",
    "\n",
    "c4 = Conv2D(filters=64, kernel_size=(3, 3), strides=(1, 1), padding='valid', activation='relu')(m3)\n",
    "m4 = MaxPool2D(pool_size=(2, 2), strides=None, padding='valid')(c4)\n",
    "drop1 = Dropout(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat = Flatten()(m4)\n",
    "d1 = Dense(1024, activation='relu')(flat)\n",
    "d2 = Dense(512, activation='relu')(d1)\n",
    "d2 = Dense(128, activation='relu')(d1)\n",
    "d3 = Dense(5, activation='relu')(d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = Softmax()(d3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(input_img, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 227, 227, 3)]     0         \n",
      "_________________________________________________________________\n",
      "rescaling (Rescaling)        (None, 227, 227, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 225, 225, 1024)    28672     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 225, 225, 1024)    0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 112, 112, 1024)    0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 112, 112, 1024)    0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 110, 110, 512)     4719104   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 110, 110, 512)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 55, 55, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 53, 53, 128)       589952    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 53, 53, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 26, 26, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 26, 26, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 24, 24, 64)        73792     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              9438208   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 645       \n",
      "_________________________________________________________________\n",
      "softmax (Softmax)            (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 14,981,573\n",
      "Trainable params: 14,981,573\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Le jeu de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227x227\n"
     ]
    }
   ],
   "source": [
    "im = Image.open('../DB/train/Rice/RicePlace1Subject1_2_bboxes_107_0.png')\n",
    "width, height = im.size\n",
    "print(f'{width}x{height}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4736 files belonging to 5 classes.\n",
      "Using 3789 files for training.\n",
      "Found 3568 files belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "train = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    '../DB/train',\n",
    "    image_size=(height, width),\n",
    "    subset='training',\n",
    "    batch_size=128,\n",
    "    seed=123,\n",
    "    label_mode='categorical',\n",
    "    validation_split=0.2)\n",
    "\n",
    "test = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    '../DB/test',\n",
    "    image_size=(height, width),\n",
    "    batch_size=128,\n",
    "    label_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    train,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
