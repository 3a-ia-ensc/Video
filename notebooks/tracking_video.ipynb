{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path, listdir\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from src.tracking import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3568 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator()\n",
    "test_generator = test_datagen.flow_from_directory('../DB/test', batch_size = 3568, class_mode = 'categorical', target_size = (227, 227))\n",
    "\n",
    "# On récupère les images d'un batch de la taille du dataset\n",
    "i = 0\n",
    "for image, lab in test_generator:\n",
    "    if i == 0: break # sinon le generator continue sa boucle (??)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tracking vidéo\n",
    "En partant d'une première détection de l'objet d'intérêt qui prend la forme d'une boite englobante que l'on suppose correcte, on va suivre l'objet sur les frames suivantes.\n",
    "\n",
    "Pour chaque frame, on prend la boîte englobante de la frame précédente, on va créer un set de nouvelles boîtes potentielles. On va ensuite récupérer le \"patch\" de l'image associé à chaque nouvelle boîte englobante et effectuer une prediction à l'aide du modèle précédemment créé. On conservera comme nouvelle boîte celle qui fournira la prédiction la plus précise (pourcentage le plus élevé)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on charge le modèle\n",
    "model = tf.keras.models.load_model('../models/best_models', custom_objects=None, compile=True, options=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 36s 318ms/step - loss: 0.0565 - accuracy: 0.9846 - categorical_accuracy: 0.9846 - recall: 0.9835 - precision: 0.9851\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.05651376023888588,\n",
       " 0.9845852255821228,\n",
       " 0.9845852255821228,\n",
       " 0.9834641218185425,\n",
       " 0.9851207137107849]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# on vérifie les performances sur le jeu de test\n",
    "model.evaluate(image, lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video 1 on 27\n",
      "Loading 186 frames\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 126/186 [04:35<04:24,  4.41s/it]"
     ]
    }
   ],
   "source": [
    "ious = []\n",
    "i = 0\n",
    "# Pour toutes les vidéos qui sont dans le jeu de test\n",
    "for file in listdir(\"../GT_test\"):\n",
    "    if file.endswith(\".txt\"):\n",
    "        i += 1\n",
    "        print(f'Video {i} on {len(listdir(\"../GT_test\"))}')\n",
    "        \n",
    "        m = re.search('(.+)_._bboxes\\.txt', file)\n",
    "        name = m.group(1)\n",
    "        \n",
    "        path_video = path.join('..', 'VIDEOS', name + '.mp4')\n",
    "        path_boxes = path.join('..', 'GT_test', file)\n",
    "        \n",
    "        label = get_label(path_video)\n",
    "        predictions, iou = tracking(model, path_video, path_boxes, label, update=None, save_fig=True)\n",
    "        mean_iou = np.mean(list(iou.values()))\n",
    "        ious.append(mean_iou)\n",
    "        print(f'Mean IoU: {np.mean(ious_move_to_data)}')\n",
    "            \n",
    "print(f'Total Mean IoU: {np.mean(ious)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Move-to-data\n",
    "Nous implémentons ici la méthode d'apprentissage incrémental \"move-to-data\" décrite dans _Move-to-Data: A new Continual Learning approach with Deep CNNs, Application for image-class recognition_\n",
    "\n",
    "Pour chaque nouvelle image, on met à jour les poids de la dernière couche du réseau en appliquant la formule suivante \n",
    "$$w_j′=w_j+(||w_j||∗\\frac{v_i}{||v_i||} − w_j)*\\epsilon$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ious_move_to_data = []\n",
    "i = 0\n",
    "# Pour toutes les vidéos qui sont dans le jeu de test\n",
    "for file in listdir(\"../GT_test\"):\n",
    "    if file.endswith(\".txt\"):\n",
    "        i += 1\n",
    "        print(f'Video {i} on {len(listdir(\"../GT_test\"))}')\n",
    "        \n",
    "        m = re.search('(.+)_._bboxes\\.txt', file)\n",
    "        name = m.group(1)\n",
    "        \n",
    "        path_video = path.join('..', 'VIDEOS', name + '.mp4')\n",
    "        path_boxes = path.join('..', 'GT_test', file)\n",
    "        \n",
    "        label = get_label(path_video)\n",
    "        \n",
    "        # on lance le tracking en activant le move-to-data, on met à jour le réseau toute les 10 images\n",
    "        predictions, iou = tracking(model, path_video, path_boxes, label, update='move-to-data', epsilon=0.0001, n_update=10, save_fig=True)\n",
    "        mean_iou = np.mean(list(iou.values()))\n",
    "        ious_move_to_data.append(mean_iou)\n",
    "        print(f'Mean IoU: {np.mean(ious_move_to_data)}')\n",
    "\n",
    "print(f'Total Mean IoU: {np.mean(ious_move_to_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on évalue les modifications apportées au modèle à l'aide des images de test\n",
    "model.evaluate(image, lab)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning\n",
    "Pour comparer la méthode move-to-data on implémente une méthode déjà éprouvée, le fine-tuning consiste à réentrainer la dernière couche du réseau avec de nouveaux batch d'image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on recharge le modèle pour ne pas écraser celui modifié par le move-to-data\n",
    "model_fine = tf.keras.models.load_model('../models/best_models', custom_objects=None, compile=True, options=None)\n",
    "\n",
    "ious_fine_tuning = []\n",
    "i = 0\n",
    "# Pour toutes les vidéos qui sont dans le jeu de test\n",
    "for file in listdir(\"../GT_test\"):\n",
    "    if file.endswith(\".txt\"):\n",
    "        i += 1\n",
    "        print(f'Video {i} on {len(listdir(\"../GT_test\"))}')\n",
    "        \n",
    "        m = re.search('(.+)_._bboxes\\.txt', file)\n",
    "        name = m.group(1)\n",
    "        \n",
    "        path_video = path.join('..', 'VIDEOS', name + '.mp4')\n",
    "        path_boxes = path.join('..', 'GT_test', file)\n",
    "        \n",
    "        label = get_label(path_video)\n",
    "        \n",
    "        # on lance le tracking en activant le fine-tuning, on met à jour le réseau toutes les 10 images\n",
    "        predictions, iou = tracking(model_fine, path_video, path_boxes, label, update='fine-tuning', epsilon=0.0001, n_update=10, save_fig=False)\n",
    "        mean_iou = np.mean(list(iou.values()))\n",
    "        ious_fine_tuning.append(mean_iou)\n",
    "        \n",
    "print(f'Mean IoU: {np.mean(ious_fine_tuning)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on évalue les modifications apportées au modèle à l'aide des images de test\n",
    "model_fine.evaluate(image, lab)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparaisons\n",
    "Dans cette partie, on compare les résultats que nous avons obtenu en tracking simple (sans mise à jour) avec les résultats que nous aurions obtenu en utilisant les modèles fournis. Cette comparaison ne sera faite que sur une seule vidéo du fait d'un temps de calcul relativement long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('../models/mobilenet_based__16.h5', custom_objects=None, compile=True, options=None)\n",
    "label = get_label('../VIDEOS/RicePlace6Subject4.mp4')\n",
    "_, iou = tracking(model, '../VIDEOS/RicePlace6Subject4.mp4', '../GT_test/RicePlace6Subject4_2_bboxes.txt', label, save_fig=True, name='mobilenet')\n",
    "mean_iou = np.mean(list(iou.values()))\n",
    "\n",
    "print(f'Mean IoU: {mean_iou}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('../models/mobilenetv2_based__6.h5', custom_objects=None, compile=True, options=None)\n",
    "label = get_label('../VIDEOS/RicePlace6Subject4.mp4')\n",
    "_, iou = tracking(model, '../VIDEOS/RicePlace6Subject4.mp4', '../GT_test/RicePlace6Subject4_2_bboxes.txt', label, save_fig=True, name='mobilenetV2')\n",
    "mean_iou = np.mean(list(iou.values()))\n",
    "\n",
    "print(f'Mean IoU: {mean_iou}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenCV Tracker\n",
    "La bibliothèque OpenCV propose nativement des trackers que nous avons également comparé au notre. Nous en avons essayé trois, qui présentent des performances différentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker_open_cvmodel('../VIDEOS/RicePlace6Subject4.mp4', '../GT_test/RicePlace6Subject4_2_bboxes.txt', 'kcf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker_open_cvmodel('../VIDEOS/RicePlace6Subject4.mp4', '../GT_test/RicePlace6Subject4_2_bboxes.txt', 'csrt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker_open_cvmodel('../VIDEOS/RicePlace6Subject4.mp4', '../GT_test/RicePlace6Subject4_2_bboxes.txt', 'mil')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
